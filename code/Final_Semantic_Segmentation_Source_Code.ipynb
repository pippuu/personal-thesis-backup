{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE2i7_0oAaUv"
      },
      "source": [
        "# Final Semantic Segmentation Source Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSSv5MxNAgFz"
      },
      "source": [
        "## Setting up packages/libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEVG3X9OQz8g"
      },
      "outputs": [],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RDVCKMbAZNV"
      },
      "outputs": [],
      "source": [
        "# Install Gdown\n",
        "!pip install gdown\n",
        "\n",
        "# Install PyTorch\n",
        "!conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cudatoolkit=11.3 -c pytorch\n",
        "# Install mim\n",
        "!pip install -U openmim\n",
        "# Install mmengine\n",
        "!mim install mmengine\n",
        "# Install MMCV\n",
        "!mim install 'mmcv >= 2.0.0rc1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mmsegmentation\n",
        "!rm -rf mmsegmentation\n",
        "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git\n",
        "%cd mmsegmentation\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "Qu2tYtAugAJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import google drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "GsskO3-f3bZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI00K-EZRrug"
      },
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check MMSegmentation installation\n",
        "import mmseg\n",
        "print(mmseg.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayEtmJWKA_Wa"
      },
      "outputs": [],
      "source": [
        "# Import pytorch\n",
        "import torch, torchvision\n",
        "\n",
        "# Import mmsegmentation\n",
        "import mmseg\n",
        "from mmseg.registry import DATASETS\n",
        "from mmseg.datasets import BaseSegDataset\n",
        "from mmseg.apis import MMSegInferencer\n",
        "from mmseg.utils import get_palette\n",
        "from mmseg.models import build_segmentor\n",
        "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
        "\n",
        "\n",
        "# Import mmengine\n",
        "import mmengine\n",
        "from mmengine import Config\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "# Import mmcv\n",
        "import mmcv\n",
        "\n",
        "# Import os\n",
        "import os\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Import PIL\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "# Import zipfile\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjpKVXv_Iq6R"
      },
      "source": [
        "## Path Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdeDkMZYIsHM"
      },
      "outputs": [],
      "source": [
        "# Path names for dataset\n",
        "data_root_dir = \"datasets/BoneScanDataset\"\n",
        "data_label_dir = os.path.join(data_root_dir, \"labels\")\n",
        "data_image_dir = os.path.join(data_root_dir, \"images\")\n",
        "data_split_dir = os.path.join(data_root_dir, \"splits\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4409kzsGI_b"
      },
      "source": [
        "## Preparing New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQnlzmBPVWEq"
      },
      "outputs": [],
      "source": [
        "# Download Bone Scan Dataset\n",
        "!gdown https://drive.google.com/uc?id=1yDYpCIJlx7rjnY0VfPcHMIg3ByD2JVA7\n",
        "!unzip \"BoneScanDatasetFinal.zip\"\n",
        "!mkdir datasets\n",
        "!mv BoneScanDataset datasets/BoneScanDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RkQhOx5U3AS"
      },
      "outputs": [],
      "source": [
        "# Define palette and classes\n",
        "classes = ('tengkorak', 'vertebra serviks', 'vertebra toraks', 'tulang rusuk', 'tulang dada', 'tulang selangka', 'tulang belikat', 'humerus', 'vertebra lumbalis', 'tulang kelangkang', 'panggul', 'tulang paha')\n",
        "palette = [\n",
        "      [176, 230,  13],\n",
        "      [0, 151, 219],\n",
        "      [126, 230, 225],\n",
        "      [166,  55, 167],\n",
        "      [230, 157, 180],\n",
        "      [167, 110,  77],\n",
        "      [121,   0,  24],\n",
        "      [56,  65, 184],\n",
        "      [230, 218,   0],\n",
        "      [230, 114,  35],\n",
        "      [13, 187,  62],\n",
        "      [230, 182,  22],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjO9CtSZbbHp"
      },
      "outputs": [],
      "source": [
        "# Test reading an image\n",
        "PIL.Image.open(os.path.join(data_image_dir, \"0.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08hALIs35wLj"
      },
      "outputs": [],
      "source": [
        "# Test reading an image\n",
        "PIL.Image.open(os.path.join(data_image_dir, \"1.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8LBFxeHvqW7"
      },
      "outputs": [],
      "source": [
        "# Test reading a label\n",
        "PIL.Image.open(os.path.join(data_label_dir, \"0.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iF-FOlBQNx8"
      },
      "outputs": [],
      "source": [
        "# Test reading a label\n",
        "PIL.Image.open(os.path.join(data_label_dir, \"1.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IbvMfg2x5NY"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the segmentation map we got for an anterior label\n",
        "img = Image.open(os.path.join(data_label_dir, \"0.png\"))\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(np.array(img.convert('RGB')))\n",
        "\n",
        "# create a patch (proxy artist) for every color\n",
        "patches = [mpatches.Patch(color=np.array(palette[i])/255,\n",
        "                          label=classes[i]) for i in range(len(classes))]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,\n",
        "           fontsize='large')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ43pdq3RNMP"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the segmentation map we got for an posterior label\n",
        "img = Image.open(os.path.join(data_label_dir, \"0.png\"))\n",
        "plt.figure(figsize=(8, 6))\n",
        "im = plt.imshow(np.array(img.convert('RGB')))\n",
        "\n",
        "# create a patch (proxy artist) for every color\n",
        "patches = [mpatches.Patch(color=np.array(palette[i])/255,\n",
        "                          label=classes[i]) for i in range(len(classes))]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.,\n",
        "           fontsize='large')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SckaaowGZ0e"
      },
      "source": [
        "## Run Inference with MMSeg trained weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXEcWXxUGfMJ"
      },
      "outputs": [],
      "source": [
        "# !wget https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b0_8x1_1024x1024_160k_cityscapes/segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth -P checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPSbBTy5xvm5"
      },
      "outputs": [],
      "source": [
        "# config_path = 'configs/segformer/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py'\n",
        "# checkpoint_path = 'checkpoints/segformer_mit-b0_8x1_1024x1024_160k_cityscapes_20211208_101857-e7f88502.pth'\n",
        "# img_path = 'demo/demo.png'\n",
        "\n",
        "# # build the model from a config file and a checkpoint file\n",
        "# model = init_model(config_path, checkpoint_path, device='cuda:0')\n",
        "\n",
        "# # inference on given image\n",
        "# result = inference_model(model, img_path)\n",
        "\n",
        "# # display the segmentation result\n",
        "# vis_image = show_result_pyplot(model, img_path, result)\n",
        "\n",
        "# PIL_image = Image.fromarray(vis_image.astype('uint8'), 'RGB')\n",
        "# PIL_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyYJ9psXILu4"
      },
      "outputs": [],
      "source": [
        "# # Normalize every labels and turn it into segmentation map\n",
        "# for item in os.listdir(os.path.join(data_anterior_dir, \"masks\")):\n",
        "#   msk = mmcv.imread((os.path.join(data_anterior_dir, \"masks\", item)))\n",
        "#   region = np.divide(msk[:,:,1], 21)\n",
        "#   np.savetxt(os.path.join(data_anterior_dir, \"masks\", \"{}.txt\".format(item.split(\".\")[0])), region)\n",
        "\n",
        "# for item in os.listdir(os.path.join(data_posterior_dir, \"masks\")):\n",
        "#   msk = mmcv.imread((os.path.join(data_posterior_dir, \"masks\", item)))\n",
        "#   region = np.divide(msk[:,:,1], 21)\n",
        "#   np.savetxt(os.path.join(data_posterior_dir, \"masks\", \"{}.txt\".format(item.split(\".\")[0])), region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jv1WCjQkTk5"
      },
      "outputs": [],
      "source": [
        "# # Check if the amount of png is the same as the txt\n",
        "# counter1, counter2 = 0, 0\n",
        "# for file in os.listdir(os.path.join(data_anterior_dir, \"masks\")):\n",
        "#   if file.endswith(\".txt\"):\n",
        "#     counter1 += 1\n",
        "#   if file.endswith(\".png\"):\n",
        "#     counter2 += 1\n",
        "# print(\"Total amount of .txt files:\", counter1)\n",
        "# print(\"Total amount of .png files:\", counter2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvw_9T99mTmz"
      },
      "outputs": [],
      "source": [
        "# # Test normalized segmentation maps\n",
        "# seg_map = np.loadtxt(os.path.join(data_anterior_dir, \"masks\", \"0.txt\")).astype(np.uint8)\n",
        "# seg_img = Image.fromarray(seg_map).convert('P')\n",
        "# seg_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0dGriefy6sV"
      },
      "source": [
        "## Splitting dataset for training, validation, and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4noASgCn_2jI"
      },
      "outputs": [],
      "source": [
        "# mmcv.mkdir_or_exist(os.path.join(data_anterior_dir, \"splits\"))\n",
        "# mmcv.mkdir_or_exist(os.path.join(data_posterior_dir, \"splits\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPtwQTJxAQZw"
      },
      "outputs": [],
      "source": [
        "# filename_list = [os.path.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "#     os.path.join(data_anterior_dir, \"labels\"), suffix='.png')]\n",
        "# len(filename_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8RRisYBbFCZ"
      },
      "outputs": [],
      "source": [
        "# len(filename_list[33:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzuD0naF2Gn_"
      },
      "outputs": [],
      "source": [
        "# # Split train/val/test set for anterior\n",
        "\n",
        "# filename_list = [os.path.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "#     os.path.join(data_anterior_dir, \"labels\"), suffix='.png')]\n",
        "# with open(os.path.join(data_anterior_dir, \"splits\", \"train.txt\"), 'w') as f:\n",
        "#   # select first 4/5 as train set\n",
        "#   train_length = int(len(filename_list)*4/5)\n",
        "#   f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "# with open(os.path.join(data_anterior_dir, \"splits\", \"val.txt\"), 'w') as f:\n",
        "#   # select last 1/5 as val set\n",
        "#   f.writelines(line + '\\n' for line in filename_list[train_length:train_length+4])\n",
        "# with open(os.path.join(data_anterior_dir, \"splits\", \"test.txt\"), 'w') as f:\n",
        "#   # select last 1/5 as test set\n",
        "#   f.writelines(line + '\\n' for line in filename_list[train_length+4:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNBCHolEc5ez"
      },
      "outputs": [],
      "source": [
        "# # Split train/val/test set for posterior\n",
        "\n",
        "# filename_list = [os.path.splitext(filename)[0] for filename in mmcv.scandir(\n",
        "#     os.path.join(data_posterior_dir, \"labels\"), suffix='.png')]\n",
        "# with open(os.path.join(data_posterior_dir, \"splits\", \"train.txt\"), 'w') as f:\n",
        "#   # select first 4/5 as train set\n",
        "#   train_length = int(len(filename_list)*4/5)\n",
        "#   f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "# with open(os.path.join(data_posterior_dir, \"splits\", \"val.txt\"), 'w') as f:\n",
        "#   # select last 1/5 as val set\n",
        "#   f.writelines(line + '\\n' for line in filename_list[train_length:train_length+4])\n",
        "# with open(os.path.join(data_posterior_dir, \"splits\", \"test.txt\"), 'w') as f:\n",
        "#   # select last 1/5 as test set\n",
        "#   f.writelines(line + '\\n' for line in filename_list[train_length+4:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-KiTUy2dwU2"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "HQnkp7wDod9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download checkpoint iteration\n",
        "# %cd /content/gdrive/MyDrive\n",
        "# if (\"pretrain\" in os.listdir()) == False:\n",
        "#   !mkdir pretrain\n",
        "# %cd /content/mmsegmentation"
      ],
      "metadata": {
        "id": "Kjybc5kykqI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rxtoF0Vo37T"
      },
      "outputs": [],
      "source": [
        "# Define global variables\n",
        "BATCH_SIZE = 3\n",
        "MAX_ITER = 6000\n",
        "VAL_INTERVAL = 600\n",
        "LOGGER_INTERVAL = 600\n",
        "CHECKPOINT_INTERVAL = 3000\n",
        "SEED = 777\n",
        "DATASET_TYPE = 'BoneScanDataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVfjnzTazhMy"
      },
      "outputs": [],
      "source": [
        "# Create custom dataset\n",
        "@DATASETS.register_module()\n",
        "class BoneScanDataset(BaseSegDataset):\n",
        "  METAINFO = dict(classes = classes, palette = palette)\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(img_suffix='.png', seg_map_suffix='.png', **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a directory to store trained_models\n",
        "!mkdir trained_models"
      ],
      "metadata": {
        "id": "H8c5LNyVLzlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a directory to store segmented_imgs\n",
        "!mkdir segmented_imgs"
      ],
      "metadata": {
        "id": "anxFJjY44Hvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSxvryn3nyiZ"
      },
      "source": [
        "### Segformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segformer MIT-B0"
      ],
      "metadata": {
        "id": "miDCoK601wAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mim download mmsegmentation --config segformer_mit-b0_8xb1-160k_cityscapes-1024x1024 --dest checkpoints"
      ],
      "metadata": {
        "id": "flqME8kS1wAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained weight\n",
        "!mkdir pretrain\n",
        "!gdown https://drive.google.com/uc?id=1NgA2QDSvnBELZBScSChlfOt1sTXY5bjq\n",
        "!mv mit_b0.pth pretrain/mit_b0.pth"
      ],
      "metadata": {
        "id": "ycWkoLjC1wAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTsQT0Rm1wAm"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "# cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# # modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'pretrain/mit_b0.pth'\n",
        "# cfg.load_from = 'checkpoints/mit_b0.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_segformer_mit_b0 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n88ix70U1wAn"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_segformer_mit_b0)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u04m8Xv1wAo"
      },
      "outputs": [],
      "source": [
        "  runner.val()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner.test()"
      ],
      "metadata": {
        "id": "x872N2t41wAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/vis_data/20230605_081951.json\"), os.path.join(dst, \"train.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230605_044627/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/20230605_081951.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/20230605_081951.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "lz0JQPvz1wAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1gMBBJPF1pmBaJzIT2-SNHM0Ra-CZPh6_\n",
        "!unzip segformer_mit-b0_8xb1-160k_cityscapes-1024x1024_lr_0001-20230606T064002Z-001.zip\n",
        "!mv segformer_mit-b0_8xb1-160k_cityscapes-1024x1024_lr_0001 trained_models/segformer_mit_b0"
      ],
      "metadata": {
        "id": "xNODMIm-1wAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir segformer_mit_b0\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/segformer_mit_b0/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/segformer_mit_b0/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/segformer_mit_b0', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "UcKGtmWg1wAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/segformer_mit_b0 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/segformer_mit_b0"
      ],
      "metadata": {
        "id": "exgG9PP51wAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('segformer_mit_b0_512channels.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/segformer_mit_b0_512channels')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp segformer_mit_b0_512channels.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "MKwr9Z1z1wAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img = mmcv.imread(os.path.join(data_image_dir, '51.png'))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ],
      "metadata": {
        "id": "Jjiw4wzo1wAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segformer MIT-B1"
      ],
      "metadata": {
        "id": "0J-xHkEc2dV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mim download mmsegmentation --config segformer_mit-b1_8xb1-160k_cityscapes-1024x1024 --dest checkpoints"
      ],
      "metadata": {
        "id": "IZFiix_z2dV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained weight\n",
        "!mkdir pretrain\n",
        "!gdown https://drive.google.com/uc?id=1V92bLc0agGL-gJp1JYutyArbVSS1GHk5\n",
        "!mv mit_b1.pth pretrain/mit_b1.pth"
      ],
      "metadata": {
        "id": "dFmWLDRf2dV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhQmtcYo2dV9"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('/content/mmsegmentation/checkpoints/segformer_mit-b1_8xb1-160k_cityscapes-1024x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512) # 65536\n",
        "# # cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# # # modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = '/content/mmsegmentation/checkpoints/segformer_mit-b1_8x1_1024x1024_160k_cityscapes_20211208_064213-655c7b3f.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_segformer_mit_b1 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8pYazOz2dV-"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_segformer_mit_b1)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD2oTUmo2dV_"
      },
      "outputs": [],
      "source": [
        "runner.val()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner.test()"
      ],
      "metadata": {
        "id": "aohwlo5B2dWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/segformer_mit_b1\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"), os.path.join(dst, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/vis_data/20230529_133154.json\"), os.path.join(dst, \"train.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_133154/20230529_133154.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_133154/20230529_133154.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))"
      ],
      "metadata": {
        "id": "Y6JjK__s2dWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=12gudsvwKrDVbF6dX4k9Z4iv3UM7indNe\n",
        "!unzip segformer_mit-b1_8xb1-160k_cityscapes-1024x1024_lr_0001-20230606T063952Z-001.zip\n",
        "!mv segformer_mit-b1_8xb1-160k_cityscapes-1024x1024_lr_0001 trained_models/segformer_mit_b1"
      ],
      "metadata": {
        "id": "_STo9GPc2dWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir segformer_mit_b1\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/segformer_mit_b1/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/segformer_mit_b1/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/segformer_mit_b1', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "lIr9Eqal2dWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/segformer_mit_b1 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/segformer_mit_b1"
      ],
      "metadata": {
        "id": "-pdAoiAQ2dWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('segformer_mit_b1_lr0001_512ch.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/segformer_mit_b1_lr0001_512ch')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp segformer_mit_b1_lr0001_512ch.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "2yWqNIbY2dWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylmyZqWO2dWE"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_6000.pth'\n",
        "# model = init_model(cfg_segformer_mit_b0, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segformer MIT-B0 512 Decoder Head Channels"
      ],
      "metadata": {
        "id": "tgvW_BAoEOoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mim download mmsegmentation --config segformer_mit-b0_8xb1-160k_cityscapes-1024x1024 --dest checkpoints"
      ],
      "metadata": {
        "id": "bd6xEgRmy9m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained weight\n",
        "!mkdir pretrain\n",
        "!gdown https://drive.google.com/uc?id=1NgA2QDSvnBELZBScSChlfOt1sTXY5bjq\n",
        "!mv mit_b0.pth pretrain/mit_b0.pth"
      ],
      "metadata": {
        "id": "t5GCRpRKiJZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21NESLkQd5G4"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "# cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# # modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.decode_head.channels = 512\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'pretrain/mit_b0.pth'\n",
        "# cfg.load_from = 'checkpoints/mit_b0.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_segformer_mit_b0 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYy-o--egcBm"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_segformer_mit_b0)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLlFm1GitMiT"
      },
      "outputs": [],
      "source": [
        "  runner.val()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner.test()"
      ],
      "metadata": {
        "id": "YaQsKxnJt62y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/segformer_mit-b0_8xb1-160k_cityscapes-1024x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/vis_data/20230605_081951.json\"), os.path.join(dst, \"train.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230605_044627/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/20230605_081951.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/20230605_081951.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_081951/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "V1O9a2cDBIYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1FMRhp_Y816lIl9UuxmEZVyO2SMJKWBxh\n",
        "!unzip segformer_mit-b0_8xb1-160k_cityscapes-1024x1024_lr_0001_512-20230606T064002Z-001.zip\n",
        "!mv segformer_mit_b0_lr_0001_512channels trained_models/segformer_mit_b0_512channels"
      ],
      "metadata": {
        "id": "za6FfZva9qoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir segformer_mit_b0_512channels\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/segformer_mit_b0_512channels/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/segformer_mit_b0_512channels/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/segformer_mit_b0_512channels', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "CSQ_AUncsE_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/segformer_mit_b0_512channels /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/segformer_mit_b0_512channels"
      ],
      "metadata": {
        "id": "gKJCmJzJ09bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('segformer_mit_b0_512channels.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/segformer_mit_b0_512channels')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp segformer_mit_b0_512channels.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "fAsS4GGc6ppk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img = mmcv.imread(os.path.join(data_image_dir, '51.png'))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ],
      "metadata": {
        "id": "vHhuHb4F0naJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Segformer MIT-B1 512 Decoder Head Channels"
      ],
      "metadata": {
        "id": "honRxPaZEdZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mim download mmsegmentation --config segformer_mit-b1_8xb1-160k_cityscapes-1024x1024 --dest checkpoints"
      ],
      "metadata": {
        "id": "gzTL7dEwEdZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained weight\n",
        "!mkdir pretrain\n",
        "!gdown https://drive.google.com/uc?id=1V92bLc0agGL-gJp1JYutyArbVSS1GHk5\n",
        "!mv mit_b1.pth pretrain/mit_b1.pth"
      ],
      "metadata": {
        "id": "gYk8wIdHEdZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3szDfiTtEdZ1"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('/content/mmsegmentation/checkpoints/segformer_mit-b1_8xb1-160k_cityscapes-1024x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512) # 65536\n",
        "# # cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "# cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "# cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "# # # modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.decode_head.channels = 512\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = '/content/mmsegmentation/checkpoints/segformer_mit-b1_8x1_1024x1024_160k_cityscapes_20211208_064213-655c7b3f.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_segformer_mit_b1 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTBTE4B5EdZ1"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_segformer_mit_b1)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfFvOfe4EdZ2"
      },
      "outputs": [],
      "source": [
        "runner.val()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runner.test()"
      ],
      "metadata": {
        "id": "iZaSZCnkEdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/segformer_mit_b1\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"), os.path.join(dst, \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/vis_data/20230529_133154.json\"), os.path.join(dst, \"train.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_133154/20230529_133154.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_133154/20230529_133154.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230529_132858/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))"
      ],
      "metadata": {
        "id": "KIYUZ16xEdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1AyyHWH1qHWYwv1OdEITsq1lEaZ7y4j1O\n",
        "!unzip segformer_mit-b1_8xb1-160k_cityscapes-1024x1024_lr_0001_512-20230606T063952Z-001.zip\n",
        "!mv segformer_mit_b1_lr0001_512ch trained_models/segformer_mit_b1_512channels"
      ],
      "metadata": {
        "id": "RQt_7jG6-eqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir segformer_mit_b1_512channels\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/segformer_mit_b1_512channels/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/segformer_mit_b1_512channels/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/segformer_mit_b1_512channels', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "pKVz0Byd--Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/segformer_mit_b1_512channels /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/segformer_mit_b1_512channels"
      ],
      "metadata": {
        "id": "bLvuW3-C1LkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('segformer_mit_b1_lr0001_512ch.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/segformer_mit_b1_lr0001_512ch')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp segformer_mit_b1_lr0001_512ch.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "wAmfiZCe_Zc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vVzg2frEdZ3"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_6000.pth'\n",
        "# model = init_model(cfg_segformer_mit_b0, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GigyUQyuaac3"
      },
      "source": [
        "### Fully Convolutional Networks (FCN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x31V-pnagRdH"
      },
      "source": [
        "\n",
        "#### FCN ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Zu-7sWCajhl"
      },
      "outputs": [],
      "source": [
        "# Download config and checkpoints\n",
        "!mim download mmsegmentation --config fcn_r18-d8_4xb2-80k_cityscapes-512x1024 --dest checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vL8OjF7aMle"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/fcn_r18-d8_4xb2-80k_cityscapes-512x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.auxiliary_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'checkpoints/fcn_r18-d8_512x1024_80k_cityscapes_20201225_021327-6c50f8b4.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_fcn_r18 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbHbyVzxbXwV"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_fcn_r18)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "runner.val()"
      ],
      "metadata": {
        "id": "7r4-Oihasrlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj0Fo7A2bf2j"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save checkpoint, config, and logs\n",
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/fcn_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"fcn_r18-d8_4xb2-80k_cityscapes-512x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_091429/vis_data/20230605_091429.json\"), os.path.join(dst, \"train.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_091429/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230603_044957/20230603_044957.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_091429/20230605_091429.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_091429/20230605_091429.log\"), os.path.join(dst, \"test.log\"))"
      ],
      "metadata": {
        "id": "BEJWXiHErMj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1u1nnbwv6b4J8Hpr9ROhIF0xJps7ug5hR\n",
        "!unzip fcn_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001-20230607T143906Z-001.zip\n",
        "!mv fcn_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001 trained_models/fcn_r18"
      ],
      "metadata": {
        "id": "FLW6CawzrBrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir fcn_r18\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/fcn_r18/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/fcn_r18/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/fcn_r18', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "pmFFhsOGrimB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/fcn_r18 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/fcn_r18"
      ],
      "metadata": {
        "id": "DBd9fDkl0ltT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('fcn_r18.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/fcn_r18')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp fcn_r18.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "bS47T48mrn61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7k22m0Vbgpk"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_10000.pth'\n",
        "# model = init_model(cfg_fcn_r18_d8, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC0xEnaOyCEN"
      },
      "source": [
        "#### FCN ResNet 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh67LxJcyCEU"
      },
      "outputs": [],
      "source": [
        "# Download config and checkpoints\n",
        "!mim download mmsegmentation --config fcn_r50-d8_4xb2-80k_cityscapes-512x1024 --dest checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cs_TlZOoyCEU"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/fcn_r50-d8_4xb2-80k_cityscapes-512x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.auxiliary_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'checkpoints/fcn_r50-d8_512x1024_80k_cityscapes_20200606_113019-03aa804d.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_fcn_r50 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Edxnf2WyCEU"
      },
      "outputs": [],
      "source": [
        "# Train the model with defined config\n",
        "runner = Runner.from_cfg(cfg_fcn_r50)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwJVExnxyCEU"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/fcn_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"fcn_r50-d8_4xb2-80k_cityscapes-512x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_093027/vis_data/20230606_093027.json\"), os.path.join(dst, \"train.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230605_044627/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_093027/20230606_093027.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_093027/20230606_093027.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_093027/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))"
      ],
      "metadata": {
        "id": "MkWvwbEbs2Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1ecWyZVmN1XAOjSQvdtE6l4B_LaGRkXUp\n",
        "!unzip fcn_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001-20230607T143917Z-001.zip\n",
        "!mv fcn_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001 trained_models/fcn_r50"
      ],
      "metadata": {
        "id": "n1ETW_fEs7Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir fcn_r50\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/fcn_r50/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/fcn_r50/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/fcn_r50', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "67_9IIv_tV0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/fcn_r50 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/fcn_r50"
      ],
      "metadata": {
        "id": "BBlTCG670tYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('fcn_r50.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/fcn_r50')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp fcn_r50.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "zzrt34W8tcKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWW01xvAyCEV"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_2500.pth'\n",
        "# model = init_model(cfg_fcn_r50_d8, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDpp2a49IX8R"
      },
      "source": [
        "### Deeplab v3+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPsCI_xGUHc0"
      },
      "source": [
        "#### DeepLabv3+ ResNet 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u99I446bI3ll"
      },
      "outputs": [],
      "source": [
        "# Download config and checkpoints\n",
        "!mim download mmsegmentation --config deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024 --dest checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEnmI4EWuTL5"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.auxiliary_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "# cfg.custom_hooks = [dict(type='EmptyCacheHook', after_epoch=True, after_iter=True)]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'checkpoints/deeplabv3plus_r18-d8_512x1024_80k_cityscapes_20201226_080942-cff257fe.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_deeplab_r18 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_P6avwJHkmK"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "runner = Runner.from_cfg(cfg_deeplab_r18)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H14I2ftcI_yq"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save checkpoint, config, and logs\n",
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_085525/vis_data/20230605_085525.json\"), os.path.join(dst, \"train.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_085525/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230603_044957/20230603_044957.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_085525/20230605_085525.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230605_085525/20230605_085525.log\"), os.path.join(dst, \"test.log\"))"
      ],
      "metadata": {
        "id": "GpZpe0_vyBDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1AMmeActlWmZenQWhSZk5_zXNIw11LTQE\n",
        "!unzip deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001-20230606T064006Z-001.zip\n",
        "!mv deeplabv3plus_r18-d8_4xb2-80k_cityscapes-512x1024_lr_0001 trained_models/deeplabv3plus_r18"
      ],
      "metadata": {
        "id": "Rtq6K03KyNNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir deeplabv3plus_r18\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/deeplabv3plus_r18/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/deeplabv3plus_r18/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/deeplabv3plus_r18', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "ZaQpH2QSyq3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/deeplabv3plus_r18 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/deeplabv3plus_r18"
      ],
      "metadata": {
        "id": "gFA1zcJzz1RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Zip folder\n",
        "# with zipfile.ZipFile('deeplabv3plus_r18.zip', 'w') as zip_file:\n",
        "#   zip_file.write('/content/mmsegmentation/segmented_imgs/deeplabv3plus_r18')\n",
        "\n",
        "# # Upload it into google drive\n",
        "# !cp deeplabv3plus_r18.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "pu9FhL1Hywk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PamA86cSxPf"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_2500.pth'\n",
        "# model = init_model(cfg_deeplab_r18_d8, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nhsN7famkBv"
      },
      "source": [
        "#### DeepLabv3+ ResNet 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0QfyxiHmkB2"
      },
      "outputs": [],
      "source": [
        "# Download config and checkpoints\n",
        "!mim download mmsegmentation --config deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024 --dest checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Dx4z-emmkB2"
      },
      "outputs": [],
      "source": [
        "cfg = Config.fromfile('checkpoints/deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024.py')\n",
        "# Since we use only one GPU, BN is used instead of SyncBN\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "# cfg.crop_size = (128, 512)\n",
        "cfg.model.data_preprocessor.size = cfg.crop_size\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
        "# modify num classes of the model in decode/auxiliary head\n",
        "cfg.model.decode_head.num_classes = 13\n",
        "cfg.model.auxiliary_head.num_classes = 13\n",
        "\n",
        "# Modify dataset type and path\n",
        "cfg.dataset_type = DATASET_TYPE\n",
        "cfg.data_root = data_root_dir\n",
        "\n",
        "cfg.train_dataloader.batch_size = BATCH_SIZE\n",
        "\n",
        "cfg.train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='RandomResize', scale=(256, 1024), ratio_range=(0.5, 2.0), keep_ratio=True),\n",
        "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
        "    dict(type='RandomFlip', prob=0.5),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='Resize', scale=(256, 1024), keep_ratio=True),\n",
        "    # add loading annotation after ``Resize`` because ground truth\n",
        "    # does not need to do resize data transform\n",
        "    dict(type='LoadAnnotations'),\n",
        "    dict(type='PackSegInputs')\n",
        "]\n",
        "\n",
        "cfg.optimizer = dict(type='AdamW', lr=0.001, weight_decay=0.0005)\n",
        "\n",
        "cfg.optim_wrapper = dict(\n",
        "    type='OptimWrapper',\n",
        "    optimizer=dict(type='AdamW', lr=0.001, weight_decay=0.0005),\n",
        "    clip_grad=dict(max_norm=1, norm_type=2))\n",
        "\n",
        "# cfg.custom_hooks = [dict(type='EmptyCacheHook', after_epoch=True, after_iter=True)]\n",
        "\n",
        "cfg.train_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.train_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
        "cfg.train_dataloader.dataset.ann_file = 'splits/train.txt'\n",
        "\n",
        "cfg.val_dataloader.dataset.type = cfg.dataset_type\n",
        "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
        "cfg.val_dataloader.dataset.data_prefix = dict(img_path=\"images\", seg_map_path=\"labels\")\n",
        "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
        "cfg.val_dataloader.dataset.ann_file = 'splits/val.txt'\n",
        "\n",
        "cfg.test_dataloader = cfg.val_dataloader\n",
        "cfg.test_dataloader.dataset.ann_file = 'splits/test.txt'\n",
        "\n",
        "\n",
        "# Load the pretrained weights\n",
        "cfg.load_from = 'checkpoints/deeplabv3plus_r50-d8_512x1024_80k_cityscapes_20200606_114049-f9fb496d.pth'\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './work_dirs/tutorial'\n",
        "\n",
        "cfg.train_cfg.max_iters = MAX_ITER\n",
        "cfg.train_cfg.val_interval = VAL_INTERVAL\n",
        "cfg.default_hooks.logger.interval = LOGGER_INTERVAL\n",
        "cfg.default_hooks.checkpoint.interval = CHECKPOINT_INTERVAL\n",
        "\n",
        "# Set seed to facilitate reproducing the result\n",
        "cfg['randomness'] = dict(seed=SEED)\n",
        "\n",
        "# Let's have a look at the final config used for training\n",
        "print(f'Config:\\n{cfg.pretty_text}')\n",
        "\n",
        "cfg_deeplab_r50 = cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2ik1zlvmkB3"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "runner = Runner.from_cfg(cfg_deeplab_r50)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc60OJm9mkB3"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/mmsegmentation/work_dirs/tutorial\"\n",
        "dst = \"/content/gdrive/MyDrive/pretrain/deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001\"\n",
        "if os.path.exists(dst) != True:\n",
        "  os.makedirs(dst)\n",
        "  print(\"Success on creating new dir.\")\n",
        "\n",
        "# Save checkpoint, config, and logs\n",
        "shutil.copy(os.path.join(src, \"iter_6000.pth\"), os.path.join(dst, \"iter_6000.pth\"))\n",
        "shutil.copy(os.path.join(src, \"deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024.py\"), os.path.join(dst, \"config.py\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_064822/vis_data/20230606_064822.json\"), os.path.join(dst, \"train.json\"))\n",
        "# shutil.copy(os.path.join(src, \"20230605_044627/20230529_132858.log\"), os.path.join(dst, \"train.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_064822/20230606_064822.json\"), os.path.join(dst, \"test.json\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_064822/20230606_064822.log\"), os.path.join(dst, \"test.log\"))\n",
        "shutil.copy(os.path.join(src, \"20230606_064822/vis_data/scalars.json\"), os.path.join(dst, \"scalars.json\"))"
      ],
      "metadata": {
        "id": "TocgJCx2vGzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download trained models\n",
        "!gdown https://drive.google.com/uc?id=1D1Pc6JlIgqMKxC3nJJ8x7zzjqI9gMxbY\n",
        "!unzip deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001-20230607T143317Z-001.zip\n",
        "!mv deeplabv3plus_r50-d8_4xb2-80k_cityscapes-512x1024_lr_0001 trained_models/deeplabv3plus_r50"
      ],
      "metadata": {
        "id": "ZDTwMY0evSS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd segmented_imgs\n",
        "!mkdir deeplabv3plus_r50\n",
        "%cd ..\n",
        "\n",
        "with open(os.path.join(data_split_dir, 'test.txt'), 'r') as f:\n",
        "    contents = f.read()\n",
        "test_data = contents.split()\n",
        "\n",
        "\n",
        "checkpoint_path ='/content/mmsegmentation/trained_models/deeplabv3plus_r50/iter_6000.pth'\n",
        "model = init_model('/content/mmsegmentation/trained_models/deeplabv3plus_r50/config.py', checkpoint_path, 'cuda:0')\n",
        "\n",
        "# Loop through the array of test dataset\n",
        "for x in test_data:\n",
        "  img = mmcv.imread(os.path.join(data_image_dir, '{}.png'.format(x)))\n",
        "  result = inference_model(model, img)\n",
        "  vis_result = show_result_pyplot(model, img, result)\n",
        "  segmented_img = Image.fromarray(vis_result)\n",
        "  segmented_img.save(os.path.join('/content/mmsegmentation/segmented_imgs/deeplabv3plus_r50', '{}.png'.format(x)))\n"
      ],
      "metadata": {
        "id": "UCh1Kn4nvodU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r segmented_imgs/deeplabv3plus_r50 /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs/deeplabv3plus_r50"
      ],
      "metadata": {
        "id": "pVKN5acu0dPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip folder\n",
        "with zipfile.ZipFile('deeplabv3plus_r50.zip', 'w') as zip_file:\n",
        "  zip_file.write('/content/mmsegmentation/segmented_imgs/deeplabv3plus_r50')\n",
        "\n",
        "# Upload it into google drive\n",
        "!cp deeplabv3plus_r50.zip /content/gdrive/MyDrive/Tugas_Akhir/segmented_imgs"
      ],
      "metadata": {
        "id": "nBSh7ORdv6SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyMhIJeOmkB3"
      },
      "outputs": [],
      "source": [
        "# # Init the model from the config and the checkpoint\n",
        "# checkpoint_path = './work_dirs/tutorial/iter_5000.pth'\n",
        "# model = init_model(cfg_deeplab_r50_d8, checkpoint_path, 'cuda:0')\n",
        "\n",
        "# img = mmcv.imread(os.path.join(data_image_dir, \"0.png\"))\n",
        "# result = inference_model(model, img)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# vis_result = show_result_pyplot(model, img, result)\n",
        "# plt.imshow(mmcv.bgr2rgb(vis_result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OndxBNBmbNid"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}